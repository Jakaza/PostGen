from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import tempfile
import os
from datetime import datetime

app = FastAPI(title="Database Schema Exporter", version="1.0.0")

# Enable CORS for frontend communication
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models for request validation
class Field(BaseModel):
    id: int
    name: str
    type: str
    isPrimary: bool = False
    isRequired: bool = False
    isForeignKey: bool = False
    referencesTable: Optional[int] = None
    referencesField: Optional[int] = None

class Table(BaseModel):
    id: int
    name: str
    fields: List[Field]

class Relationship(BaseModel):
    id: int
    fromTable: int
    fromField: int
    toTable: int
    toField: int

class SchemaRequest(BaseModel):
    tables: List[Table]
    relationships: List[Relationship]
    tablePositions: Optional[Dict[str, Any]] = None

class PostgreSQLGenerator:
    def __init__(self):
        self.type_mapping = {
            'INTEGER': 'INTEGER',
            'VARCHAR(255)': 'VARCHAR(255)',
            'TEXT': 'TEXT',
            'BOOLEAN': 'BOOLEAN',
            'TIMESTAMP': 'TIMESTAMP',
            'DATE': 'DATE',
            'DECIMAL': 'DECIMAL(10,2)',
            'FLOAT': 'REAL',
            'UUID': 'UUID',
            'JSON': 'JSONB',
            'VARCHAR(50)': 'VARCHAR(50)',
            'VARCHAR(100)': 'VARCHAR(100)'
        }
    
    def map_data_type(self, field_type: str) -> str:
        """Map frontend data types to PostgreSQL types"""
        return self.type_mapping.get(field_type, 'TEXT')
    
    def generate_table_sql(self, table: Table, tables_dict: Dict[int, Table], relationships: List[Relationship]) -> str:
        """Generate CREATE TABLE SQL for a single table"""
        sql_lines = [f"CREATE TABLE {table.name} ("]
        
        # Generate field definitions
        field_definitions = []
        foreign_key_constraints = []
        
        for field in table.fields:
            field_def = f"    {field.name} {self.map_data_type(field.type)}"
            
            # Add constraints
            if field.isRequired or field.isPrimary:
                field_def += " NOT NULL"
            
            if field.isPrimary:
                field_def += " PRIMARY KEY"
            
            field_definitions.append(field_def)
            
            # Handle foreign key constraints
            if field.isForeignKey and field.referencesTable and field.referencesField:
                referenced_table = tables_dict.get(field.referencesTable)
                if referenced_table:
                    referenced_field = next(
                        (f for f in referenced_table.fields if f.id == field.referencesField), 
                        None
                    )
                    if referenced_field:
                        fk_constraint = f"    FOREIGN KEY ({field.name}) REFERENCES {referenced_table.name}({referenced_field.name})"
                        foreign_key_constraints.append(fk_constraint)

            elif field.isForeignKey:
                for rel in relationships:
                    if rel.fromTable == table.id and rel.fromField == field.id:
                        referenced_table = tables_dict.get(rel.toTable)
                        if referenced_table:
                            referenced_field = next(
                                (f for f in referenced_table.fields if f.id == rel.toField),
                                None
                            )
                            if referenced_field:
                                fk_constraint = f"    FOREIGN KEY ({field.name}) REFERENCES {referenced_table.name}({referenced_field.name})"
                                foreign_key_constraints.append(fk_constraint)
        
        all_definitions = field_definitions + foreign_key_constraints
        sql_lines.append(",\n".join(all_definitions))
        sql_lines.append(");")
        
        return "\n".join(sql_lines)
    
    def generate_indexes_sql(self, table: Table) -> List[str]:
        """Generate CREATE INDEX SQL for foreign keys and other indexed fields"""
        indexes = []
        
        for field in table.fields:
            if field.isForeignKey:
                index_name = f"idx_{table.name}_{field.name}"
                index_sql = f"CREATE INDEX {index_name} ON {table.name}({field.name});"
                indexes.append(index_sql)
        
        return indexes
    
    def generate_comments_sql(self, table: Table, relationships: List[Relationship]) -> List[str]:
        """Generate COMMENT SQL for documentation"""
        comments = []
        
        # Table comment
        table_comment = f"COMMENT ON TABLE {table.name} IS 'Generated by Database Table Designer';"
        comments.append(table_comment)
        
        # Field comments
        for field in table.fields:
            field_info = []
            if field.isPrimary:
                field_info.append("Primary Key")
            if field.isForeignKey:
                field_info.append("Foreign Key")
            if field.isRequired:
                field_info.append("Required")
            
            if field_info:
                comment_text = ", ".join(field_info)
                field_comment = f"COMMENT ON COLUMN {table.name}.{field.name} IS '{comment_text}';"
                comments.append(field_comment)
        
        return comments
    
    def generate_full_schema(self, schema_request: SchemaRequest) -> str:
        """Generate complete PostgreSQL schema"""
        sql_parts = []
        
        # Header comment
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        header = f"""-- PostgreSQL Database Schema
-- Generated by Database Table Designer
-- Created: {timestamp}
-- 
-- This file contains the complete database schema including:
-- - Table definitions
-- - Foreign key constraints
-- - Indexes for performance
-- - Comments for documentation

-- Enable UUID extension if needed
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

"""
        sql_parts.append(header)
        
        # Create dictionary for easy table lookup
        tables_dict = {table.id: table for table in schema_request.tables}
        
        # Sort tables to handle dependencies (tables with no foreign keys first)
        def get_dependency_order(tables: List[Table]) -> List[Table]:
            """Sort tables to minimize foreign key dependency issues"""
            no_fk_tables = [t for t in tables if not any(f.isForeignKey for f in t.fields)]
            has_fk_tables = [t for t in tables if any(f.isForeignKey for f in t.fields)]
            return no_fk_tables + has_fk_tables
        
        sorted_tables = get_dependency_order(schema_request.tables)
        
        # Generate DROP TABLE statements (in reverse order)
        sql_parts.append("-- Drop tables if they exist (in reverse dependency order)")
        for table in reversed(sorted_tables):
            sql_parts.append(f"DROP TABLE IF EXISTS {table.name} CASCADE;")
        sql_parts.append("")
        
        # Generate CREATE TABLE statements
        sql_parts.append("-- Create tables")
        for table in sorted_tables:
            table_sql = self.generate_table_sql(table, tables_dict)
            sql_parts.append(table_sql)
            sql_parts.append("")
        
        # Generate indexes
        sql_parts.append("-- Create indexes for foreign keys")
        for table in schema_request.tables:
            indexes = self.generate_indexes_sql(table)
            sql_parts.extend(indexes)
        if any(self.generate_indexes_sql(table) for table in schema_request.tables):
            sql_parts.append("")
        
        # Generate comments
        sql_parts.append("-- Add comments for documentation")
        for table in schema_request.tables:
            comments = self.generate_comments_sql(table, schema_request.relationships)
            sql_parts.extend(comments)
        sql_parts.append("")
        
        # Add sample data insert templates (commented out)
        sql_parts.append("-- Sample data insert templates (uncomment and modify as needed)")
        for table in schema_request.tables:
            field_names = [f.name for f in table.fields]
            field_placeholders = ["'value'" if not f.isPrimary or f.name != 'id' else "DEFAULT" for f in table.fields]
            
            insert_template = f"-- INSERT INTO {table.name} ({', '.join(field_names)}) VALUES ({', '.join(field_placeholders)});"
            sql_parts.append(insert_template)
        
        return "\n".join(sql_parts)

@app.get("/")
async def root():
    return {"message": "Database Schema Exporter API", "status": "running"}

@app.post("/export-schema")
async def export_schema(schema_request: SchemaRequest):
    """
    Convert database schema to PostgreSQL SQL file and return for download
    """
    try:
        # Validate that we have tables
        if not schema_request.tables:
            raise HTTPException(status_code=400, detail="No tables provided")
        
        # Generate PostgreSQL SQL
        generator = PostgreSQLGenerator()
        sql_content = generator.generate_full_schema(schema_request)
        
        # Create temporary file
        with tempfile.NamedTemporaryFile(mode='w', suffix='.sql', delete=False, encoding='utf-8') as temp_file:
            temp_file.write(sql_content)
            temp_file_path = temp_file.name
        
        # Generate filename with timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"database_schema_{timestamp}.sql"
        
        # Return file for download
        return FileResponse(
            path=temp_file_path,
            filename=filename,
            media_type='application/sql',
            headers={
                "Content-Disposition": f"attachment; filename={filename}"
            }
        )
    
    except Exception as e:
        # Clean up temp file if it was created
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
        raise HTTPException(status_code=500, detail=f"Error generating SQL: {str(e)}")

@app.post("/validate-schema")
async def validate_schema(schema_request: SchemaRequest):
    """
    Validate the database schema and return any issues
    """
    issues = []
    
    # Check for empty table names
    for table in schema_request.tables:
        if not table.name.strip():
            issues.append(f"Table ID {table.id} has empty name")
        
        # Check for empty field names
        for field in table.fields:
            if not field.name.strip():
                issues.append(f"Table '{table.name}' has field with empty name")
        
        # Check for duplicate field names
        field_names = [f.name for f in table.fields]
        if len(field_names) != len(set(field_names)):
            issues.append(f"Table '{table.name}' has duplicate field names")
        
        # Check for primary key
        primary_keys = [f for f in table.fields if f.isPrimary]
        if len(primary_keys) == 0:
            issues.append(f"Table '{table.name}' has no primary key")
        elif len(primary_keys) > 1:
            issues.append(f"Table '{table.name}' has multiple primary keys")
    
    # Check for duplicate table names
    table_names = [t.name for t in schema_request.tables]
    if len(table_names) != len(set(table_names)):
        issues.append("Duplicate table names found")
    
    # Validate foreign key relationships
    table_ids = {t.id for t in schema_request.tables}
    for relationship in schema_request.relationships:
        if relationship.fromTable not in table_ids:
            issues.append(f"Relationship references non-existent fromTable ID: {relationship.fromTable}")
        if relationship.toTable not in table_ids:
            issues.append(f"Relationship references non-existent toTable ID: {relationship.toTable}")
    
    return {
        "valid": len(issues) == 0,
        "issues": issues,
        "table_count": len(schema_request.tables),
        "relationship_count": len(schema_request.relationships)
    }

@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)